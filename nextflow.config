nextflow.enable.dsl = 2

conda {
    enabled = true
    // Set the conda create timeout to verify environment being used for each process
    createTimeout = '1h' 
}

/* Define profiles for config files
 * Nextflow requires the custom config files to be 
 * defined in the nextflow.config file as a profile, 
 * to be able to reference the params in this file.
*/
profiles {
    slurm {
        process {
            queue = 'genoa64'
            executor = "slurm"
            clusterOptions = '--qos=short'
        }
    }
    '250221_OAKseq_Nvec' {
        includeConfig 'config/250221_OAKseq_Nvec.config'
    }
    '250403_OAKseq_Nvec' {
        includeConfig 'config/250403_OAKseq_Nvec.config'
    }
}


// Set default parameters
params {
    // Directory parameters
    code_dir =              "${task.workDir}"
    output_dir =            "${task.workDir}/.."
    fastq_dir =             null
    protocol =              null
    seqspec_file =          null
    parsebio_groups =       [[]]

    // Reference parameters
    ref_fasta =             null
    ref_gtf =               null
    ref_parse_gtf =         "${params.ref_gtf}"
    mt_contig =             "^MT"
    grep_rrna =             "rRNA"

    mapping_software =      "starsolo"

    // Conditional parameters
    perform_geneext =           true
    perform_featurecounts =     true
    perform_kraken =            true
    perform_cellbender =        false
    kraken_db_path =            null

    // Commercial software
    cellranger_dir =            null
    bdrhap_pipeline_dir =       null
    parsebio_pipeline_dir =     null
}


process {
    conda = "${params.code_dir}/env/bca_env.yml"
    cache = 'lenient'
    queue = 'genoa64'
    executor = "slurm"

    // Default resources
    stageInMode = 'symlink'
    stageOutMode = 'move'
    clusterOptions = '--qos=short'
    cpus = '1'
    memory = 6.GB
    time = '3h'

    // Process-specific resources
    withName: 'KRAKEN_CREATE_DB' {
        clusterOptions = '--qos=shorter'
        memory = 48.GB
        time = '2h'
    }

    withName: 'KRAKEN' {
        conda = "${params.code_dir}/env/kraken_env.yml"
        clusterOptions = '--qos=short'
        memory = 48.GB
        cpus = 4
        time = '5h'
    }

    // Process-specific resources: parse_workflow()
    withName: 'PARSEBIO_PIPELINE_DEMUX' {
        clusterOptions = '--qos=shorter'
        cpus = 1
        memory = 20.GB
        time = '2h'
    }

    withName: 'PARSEBIO_PIPELINE_MKREF' {
        conda = "${params.code_dir}/env/spipe_env.yml"
        clusterOptions = '--qos=shorter'
        cpus = 1
        memory = 20.GB
        time = '2h'
    }

    withName: 'PARSEBIO_PIPELINE' {
        conda = "${params.code_dir}/env/spipe_env.yml"
        clusterOptions = '--qos=short'
        cpus = 4 
        time = '5h' 
        memory = '32 GB' 
    }


    // Process-specific resources: bd_rhapsody_workflow()
    withName: 'RM_VARBASES' {
        clusterOptions = '--qos=short'
        memory = 32.GB
        time = '5h'
    }

    withName: 'BDRHAP_PIPELINE_MKREF' {
        conda = "${params.code_dir}/env/bd_pipe_env.yml"
        clusterOptions = '--qos=shorter'
        cpus = 1
        memory = 24.GB
        time = '2h'
    }

    withName: 'BDRHAP_PIPELINE' {
        conda = "${params.code_dir}/env/bd_pipe_env.yml"
        clusterOptions = '--qos=normal'
        cpus = 4
        memory = 86.GB
        time = '10h'
    }

    // Process-specific resources: oak_seq_workflow()
    withName: 'CR_PIPELINE_MKREF' {
        clusterOptions = '--qos=shorter'
        cpus = 1
        memory = 24.GB
        time = '1h'
    }

    withName: 'CR_PIPELINE' {
        clusterOptions = '--qos=normal'
        cpus = 4
        memory = 32.GB
        time = '7h'
    }

    // Process-specific resources: QC_mapping_workflow()
    withName: 'GENINDEX_STARSOLO' {
        clusterOptions = '--qos=shorter'
        cpus = 4
        memory = 64.GB
        time = '2h'
        ext.args = { params.annot_type == 'GFF' ? '--sjdbGTFtagExonParentTranscript mRNA' : '' }
    }

    withName: 'MAPPING_STARSOLO' {
        clusterOptions = { (params.protocol == 'bd_rhapsody' || params.protocol == 'oak_seq') ? '--qos=vlong' : '--qos=short' }
        memory = { (params.protocol == 'bd_rhapsody' || params.protocol == 'oak_seq') ? '112 GB' : '32 GB' }
        cpus = { (params.protocol == 'bd_rhapsody' || params.protocol == 'oak_seq') ? 8 : 4 }
        time = { (params.protocol == 'bd_rhapsody' || params.protocol == 'oak_seq') ? '28h' : '5h' }
        ext.args = { (params.protocol == 'bd_rhapsody' || params.protocol == 'oak_seq') ? '--limitBAMsortRAM 7485893740' : '' }
    }

    withName: 'GENINDEX_ALEVIN' {
        conda = "${params.code_dir}/env/alevin_env.yml"
        clusterOptions = '--qos=short'
        cpus = 4
        memory = 64.GB
        time = '4h'
    }

    withName: 'MAPPING_ALEVIN' {
        conda = "${params.code_dir}/env/alevin_env.yml"
        clusterOptions = '--qos=short'
        cpus = 4
        memory = 64.GB
        time = '5h'
    }

    withName: 'GENE_EXT' {
        conda = "${params.code_dir}/env/geneext_env.yml"
        clusterOptions = '--qos=shorter'
        memory = 64.GB
        cpus = 4
        time = '2h'
    }

    // Process-specific resources: filtering_workflow()
    withName: 'CELLBENDER' {
        conda = "${params.code_dir}/env/cellbender_env.yml"
        clusterOptions = '--qos=long'
        memory = 64.GB
        cpus = 8
        time = '16h'
    }
}


// Automatically removes work directories of succesful jobs to reduce storage
// cleanup = true

// Manifest
manifest {
    name = 'BCA Pre-processing Pipeline'
    author = 'Bonita van Waardenburg'
    description = 'Biodiversity Cell Atlas Pre-processing Pipeline'
    version = '1.0.0'
    nextflowVersion = '>=21.04.0'
}


/* Execution reports
 * report: 	creates execution report, including summary,
 * 			resources and tasks.
 *  dag :	creates a workflow diagram of the pipeline. 
 * 			vertices in the graph represent the pipelineâ€™s 
 *  		processes and operators, while the edges represent 
 * 			the data dependencies (i.e. channels) between them.
 * timeline : 	creates execution timeline, displaying the 
 *  			execution-, waiting- and staging times.
*/
report {
    enabled = true
    file = "${params.output_dir}/pipeline_info/execution_report.html"
    overwrite = true
    showTaskResources = true
    showTaskResourcesPercentage = true
}

timeline {
    enabled = true
    file = "${params.output_dir}/pipeline_info/execution_timeline.html"
    overwrite = true
}

trace {
    enabled = true
    file = "${params.output_dir}/pipeline_info/execution_trace.txt"
    overwrite = true
}

dag {
    enabled = true
    file = "${params.output_dir}/pipeline_info/pipeline_dag.svg"
    overwrite = true
}
